<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="will"><meta name="keywords" content="will"><meta name="description" content="什么是大型语言模型（LLM）大型语言模型（LLM）的概念大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型。 LLM 通常指包含数百亿（或更多）参数的语言模型，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知名 LLM 有 GPT-3.5、GPT-4、PaLM、Claude 和 LLaMA 等，国内"><meta property="og:type" content="article"><meta property="og:title" content="大型语言模型（LLM）理论简介"><meta property="og:url" content="https://github.com/yangxiangnanwill/yangxiangnanwill.github.io/2026/01/04/%E5%A5%BD%E5%A5%BD%E7%A0%81%E4%BB%A3%E7%A0%81%E5%90%96/LLM/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E7%90%86%E8%AE%BA%E7%AE%80%E4%BB%8B/index.html"><meta property="og:site_name" content="Will"><meta property="og:description" content="什么是大型语言模型（LLM）大型语言模型（LLM）的概念大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型。 LLM 通常指包含数百亿（或更多）参数的语言模型，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知名 LLM 有 GPT-3.5、GPT-4、PaLM、Claude 和 LLaMA 等，国内"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2026-01-04T02:06:38.333Z"><meta property="article:modified_time" content="2026-01-04T07:48:11.724Z"><meta property="article:author" content="will"><meta property="article:tag" content="LLM"><meta property="article:tag" content="人工智能"><meta name="twitter:card" content="summary_large_image"><title>大型语言模型（LLM）理论简介 - Will</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var dntVal,Fluid=window.Fluid||{},CONFIG=(Fluid.ctx=Object.assign({},Fluid.ctx),{hostname:"github.com",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"});CONFIG.web_analytics.follow_dnt&&(dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on")))</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.4.2"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>WILL</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="大型语言模型（LLM）理论简介"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2026-01-04 10:06" pubdate>2026年1月4日 上午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 5.2k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 44 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">大型语言模型（LLM）理论简介</h1><div class="markdown-body"><h1 id="什么是大型语言模型（LLM）"><a href="#什么是大型语言模型（LLM）" class="headerlink" title="什么是大型语言模型（LLM）"></a>什么是大型语言模型（LLM）</h1><h2 id="大型语言模型（LLM）的概念"><a href="#大型语言模型（LLM）的概念" class="headerlink" title="大型语言模型（LLM）的概念"></a>大型语言模型（LLM）的概念</h2><p>大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型。</p><p>LLM 通常指包含数百亿（或更多）参数的语言模型，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知名 LLM 有 GPT-3.5、GPT-4、PaLM、Claude 和 LLaMA 等，国内的有文心一言、讯飞星火、通义千问、ChatGLM、百川等。</p><p>为了探索性能的极限，许多研究人员开始训练越来越庞大的语言模型，例如拥有 1750 亿参数的 GPT-3 和 5400 亿参数的 PaLM 。尽管这些大型语言模型与小型语言模型（例如 3.3 亿参数的 BERT 和 15 亿参数的 GPT-2）使用相似的架构和预训练任务，但它们展现出截然不同的能力，尤其在解决复杂任务时表现出了惊人的潜力，这被称为“涌现能力”。以 GPT-3 和 GPT-2 为例，GPT-3 可以通过学习上下文来解决少样本任务，而 GPT-2 在这方面表现较差。因此，科研界给这些庞大的语言模型起了个名字，称之为“大语言模型（LLM）”。LLM 的一个杰出应用就是 ChatGPT ，它是 GPT 系列 LLM 用于与人类对话式应用的大胆尝试，展现出了非常流畅和自然的表现。</p><h2 id="LLM-的发展历程"><a href="#LLM-的发展历程" class="headerlink" title="LLM 的发展历程"></a>LLM 的发展历程</h2><p>语言建模的研究可以追溯到20 世纪 90 年代，当时的研究主要集中在采用统计学习方法来预测词汇，通过分析前面的词汇来预测下一个词汇。但在理解复杂语言规则方面存在一定局限性。</p><p>随后，研究人员不断尝试改进，2003 年深度学习先驱 Bengio 在他的经典论文 《A Neural Probabilistic Language Model》中，首次将深度学习的思想融入到语言模型中。强大的神经网络模型，相当于为计算机提供了强大的”大脑”来理解语言，让模型可以更好地捕捉和理解语言中的复杂关系。</p><p>2018 年左右，Transformer 架构的神经网络模型开始崭露头角。通过大量文本数据训练这些模型，使它们能够通过阅读大量文本来深入理解语言规则和模式，就像让计算机阅读整个互联网一样，对语言有了更深刻的理解，极大地提升了模型在各种自然语言处理任务上的表现。</p><p>与此同时，研究人员发现，随着语言模型规模的扩大（增加模型大小或使用更多数据），模型展现出了一些惊人的能力，在各种任务中的表现均显著提升。这一发现标志着大型语言模型（LLM）时代的开启。</p><h2 id="常见的-LLM-模型"><a href="#常见的-LLM-模型" class="headerlink" title="常见的 LLM 模型"></a>常见的 LLM 模型</h2><p>主要介绍几个国内外常见的大模型（包括开源和闭源）。</p><h3 id="闭源-LLM-未公开源代码"><a href="#闭源-LLM-未公开源代码" class="headerlink" title="闭源 LLM (未公开源代码)"></a>闭源 LLM (未公开源代码)</h3><h4 id="GPT-系列"><a href="#GPT-系列" class="headerlink" title="GPT 系列"></a>GPT 系列</h4><p>OpenAI 公司在 2018 年提出的 GPT（Generative Pre-Training） 模型是典型的 生成式预训练语言模型 之一。</p><p>GPT 模型的基本原则是通过语言建模将世界知识压缩到仅解码器 (decoder-only) 的 Transformer 模型中，这样它就可以恢复(或记忆)世界知识的语义，并充当通用任务求解器。它能够成功的两个关键点：</p><ul><li>训练能够准确预测下一个单词的 decoder-only 的 Transformer 语言模型</li><li>扩展语言模型的大小</li></ul><h5 id="ChatGPT"><a href="#ChatGPT" class="headerlink" title="ChatGPT"></a>ChatGPT</h5><blockquote><p><a target="_blank" rel="noopener" href="https://chat.openai.com/">ChatGPT 使用地址</a></p></blockquote><p><code>2022 年 11 月</code>，<strong>OpenAI</strong> 发布了基于 GPT 模型（GPT-3.5 和 GPT-4） 的<strong>会话应用 ChatGPT</strong>。由于与人类交流的出色能力，ChatGPT 自发布以来就引发了人工智能社区的兴奋。ChatGPT 是基于强大的 GPT 模型开发的，具有特别优化的会话能力。</p><p>ChatGPT 从本质上来说是一个 LLM 应用，是基于基座模型开发出来的，与基座模型有本质的区别。其支持 GPT-3.5 和 GPT-4 两个版本。</p><p>现在的 ChatGPT 支持最长达 32,000 个字符，知识截止日期是 2021 年 9 月，它可以执行各种任务，包括<strong>代码编写、数学问题求解、写作建议</strong>等。ChatGPT 在与人类交流方面表现出了卓越的能力：拥有丰富的知识储备，对数学问题进行推理的技能，在多回合对话中准确追踪上下文，并且与人类安全使用的价值观非常一致。后来，ChatGPT 支持插件机制，这进一步扩展了 ChatGPT 与现有工具或应用程序的能力。到目前为止，它似乎是人工智能历史上最强大的聊天机器人。ChatGPT 的推出对未来的人工智能研究具有重大影响，它为探索类人人工智能系统提供了启示。</p><h5 id="GPT-4"><a href="#GPT-4" class="headerlink" title="GPT-4"></a>GPT-4</h5><p><code>2023 年 3 月</code>发布的 GPT-4，它将<strong>文本输入扩展到多模态信号</strong>。GPT3.5 拥有 1750 亿 个参数，而 GPT4 的参数量官方并没有公布，但有相关人员猜测，GPT-4 在 120 层中总共包含了 1.8 万亿参数，也就是说，GPT-4 的规模是 GPT-3 的 10 倍以上。因此，GPT-4 比 GPT-3.5 <strong>解决复杂任务的能力更强，在许多评估任务上表现出较大的性能提升</strong>。</p><p>最近的一项研究通过对人为生成的问题进行定性测试来研究 GPT-4 的能力，这些问题包含了各种各样的困难任务，并表明 GPT-4 可以比之前的 GPT 模型(如 GPT3.5 )实现更优越的性能。此外，由于六个月的迭代校准(在 RLHF 训练中有额外的安全奖励信号)，GPT-4 对恶意或挑衅性查询的响应更安全，并应用了一些干预策略来缓解 LLM 可能出现的问题，如幻觉、隐私和过度依赖。</p><blockquote><p>注意：2023 年 11 月 7 日， OpenAI 召开了首个开发者大会，会上推出了最新的大语言模型 GPT-4 Turbo，Turbo 相当于进阶版。它将上下文长度扩展到 128k，相当于 300 页文本，并且训练知识更新到 2023 年 4 月</p></blockquote><p>GPT3.5 是免费的，而 GPT-4 是收费的。需要开通 plus 会员 20 美元&#x2F;月。</p><h4 id="Claude系列"><a href="#Claude系列" class="headerlink" title="Claude系列"></a>Claude系列</h4><p>Claude 系列模型是由 OpenAI 离职人员创建的 <strong>Anthropic</strong> 公司开发的闭源语言大模型。</p><blockquote><p><a target="_blank" rel="noopener" href="https://claude.ai/chats">Claude 使用地址</a></p></blockquote><p>最早的 <strong>Claude</strong> 于 <code>2023 年 3 月 15 日</code>发布，在 2023 年 7 月 11 日，更新至 <strong>Claude-2</strong>， 并在 <code>2024 年 3 月 4 日</code>更新至 <strong>Claude-3</strong>。</p><p>Claude 3 系列包括三个不同的模型，分别是 Claude 3 Haiku、Claude 3 Sonnet 和 Claude 3 Opus，它们的能力依次递增，旨在满足不同用户和应用场景的需求。</p><table><thead><tr><th align="center">模型名称</th><th align="center">上下文长度</th><th align="center">特点</th><th align="center">input 费用($&#x2F;1M tokens)</th><th align="center">output 费用($&#x2F;1M tokens)</th></tr></thead><tbody><tr><td align="center">Claude 3 Haiku</td><td align="center">200k</td><td align="center">速度最快</td><td align="center">0.25</td><td align="center">1.25</td></tr><tr><td align="center">Claude 3 Sonnet</td><td align="center">200k</td><td align="center">平衡</td><td align="center">3git</td><td align="center">15</td></tr><tr><td align="center">Claude 3 Opus</td><td align="center">200k</td><td align="center">性能最强</td><td align="center">15</td><td align="center">75</td></tr></tbody></table><h4 id="PaLM-x2F-Gemini-系列"><a href="#PaLM-x2F-Gemini-系列" class="headerlink" title="PaLM&#x2F;Gemini 系列"></a>PaLM&#x2F;Gemini 系列</h4><p><strong>PaLM 系列</strong>语言大模型由 <strong>Google</strong> 开发。其初始版本于 <code>2022 年 4 月</code>发布，并在 2023 年 3 月公开了 API。2023 年 5 月，Google 发布了 <strong>PaLM 2</strong>，<code>2024 年 2 月 1 日</code>，Google 将 Bard(之前发布的对话应用) 的底层大模型驱动由 PaLM2 更改为 <strong>Gemini</strong>，同时也将原先的 Bard 更名为 <strong>Gemini</strong>。</p><blockquote><p><a target="_blank" rel="noopener" href="https://ai.google/discover/palm2/">PaLM 官方地址</a></p></blockquote><blockquote><p><a target="_blank" rel="noopener" href="https://gemini.google.com/">Gemini 使用地址</a></p></blockquote><p>目前的 Gemini 是第一个版本，即 Gemini 1.0，根据参数量不同分为 Ultra, Pro 和 Nano 三个版本。</p><h4 id="文心一言"><a href="#文心一言" class="headerlink" title="文心一言"></a>文心一言</h4><blockquote><p><a target="_blank" rel="noopener" href="https://yiyan.baidu.com/">文心一言使用地址</a></p></blockquote><p><strong>文心一言是基于百度文心大模型的知识增强语言大模型</strong>，于 <code>2023 年 3 月</code>在国内率先开启邀测。文心一言的基础模型文心大模型于 2019 年发布 1.0 版，现已更新到 <strong>4.0</strong> 版本。更进一步划分，文心大模型包括 NLP 大模型、CV 大模型、跨模态大模型、生物计算大模型、行业大模型。中文能力相对来说非常不错的闭源模型。</p><p>文心一言网页版分为<strong>免费版</strong>和<strong>专业版</strong>。</p><ul><li>免费版使用文心 3.5 版本，已经能够满足个人用户或小型企业的大部分需求。</li><li>专业版使用文心 4.0 版本。定价为 59.9 元&#x2F;月，连续包月优惠价为 49.9 元&#x2F;月</li></ul><p>同时也可以使用 API 进行调用（<a target="_blank" rel="noopener" href="https://console.bce.baidu.com/qianfan/chargemanage/list">计费详情</a>）。</p><h4 id="星火大模型"><a href="#星火大模型" class="headerlink" title="星火大模型"></a>星火大模型</h4><blockquote><p><a target="_blank" rel="noopener" href="https://xinghuo.xfyun.cn/">星火大模型使用地址</a></p></blockquote><p><strong>讯飞星火认知大模型</strong>是<strong>科大讯飞</strong>发布的语言大模型，支持多种自然语言处理任务。该模型于 <code>2023 年 5 月</code>首次发布，后续经过多次升级。<code>2023 年 10 月</code>，讯飞发布了<strong>讯飞星火认知大模型 V3.0</strong>。<code>2024 年 1 月</code>，讯飞发布了<strong>讯飞星火认知大模型 V3.5</strong>，在语言理解，文本生成，知识问答等七个方面进行了升级，并且支持 system 指令，插件调用等多项功能。</p><h3 id="开源LLM"><a href="#开源LLM" class="headerlink" title="开源LLM"></a>开源LLM</h3><h4 id="LLaMA-系列"><a href="#LLaMA-系列" class="headerlink" title="LLaMA 系列"></a>LLaMA 系列</h4><blockquote><p><a target="_blank" rel="noopener" href="https://llama.meta.com/">LLaMA 官方地址</a></p></blockquote><blockquote><p><a href="https://github.com/facebookresearch/llama">LLaMA 开源地址</a></p></blockquote><p><strong>LLaMA 系列模型</strong>是 <strong>Meta</strong> 开源的一组参数规模 <strong>从 7B 到 70B</strong> 的基础语言模型。LLaMA 于<code>2023 年 2 月</code>发布，并于 <code>2023 年 7 月</code>发布了 <strong>LLaMA2</strong> 模型。它们都是在数万亿个字符上训练的，展示了如何<strong>仅使用公开可用的数据集来训练最先进的模型</strong>，而不需要依赖专有或不可访问的数据集。这些数据集包括 Common Crawl、Wikipedia、OpenWebText2、RealNews、Books 等。LLaMA 模型使用了<strong>大规模的数据过滤和清洗技术</strong>，以提高数据质量和多样性，减少噪声和偏见。LLaMA 模型还使用了高效的<strong>数据并行</strong>和<strong>流水线并行</strong>技术，以加速模型的训练和扩展。特别地，LLaMA 13B 在 CommonsenseQA 等 9 个基准测试中超过了 GPT-3 (175B)，而 <strong>LLaMA 65B 与最优秀的模型 Chinchilla-70B 和 PaLM-540B 相媲美</strong>。LLaMA 通过使用更少的字符来达到最佳性能，从而在各种推理预算下具有优势。</p><p>与 GPT 系列相同，LLaMA 模型也采用了 <strong>decoder-only</strong> 架构，同时结合了一些前人工作的改进：</p><ul><li><code>Pre-normalization 正则化</code>：为了提高训练稳定性，LLaMA 对每个 Transformer 子层的输入进行了 RMSNorm 归一化，这种归一化方法可以避免梯度爆炸和消失的问题，提高模型的收敛速度和性能；</li><li><code>SwiGLU 激活函数</code>：将 ReLU 非线性替换为 SwiGLU 激活函数，增加网络的表达能力和非线性，同时减少参数量和计算量；</li><li><code>旋转位置编码（RoPE，Rotary Position Embedding）</code>：模型的输入不再使用位置编码，而是在网络的每一层添加了位置编码，RoPE 位置编码可以有效地捕捉输入序列中的相对位置信息，并且具有更好的泛化能力。</li></ul><p><strong>LLaMA2</strong> 在 LLaMA 系列模型的基础上进行了改进，提高了模型的性能和效率：</p><ul><li><code>更多的训练数据量</code>：LLaMA2 在 2 万亿个 token 的数据上进行预训练，相比 LLaMA1 的训练数据量增加了 40%。LLaMA2 能够接触到更多的文本信息，从而提高了其理解和生成文本的能力。</li><li><code>更长的上下文长度</code>：LLaMA2 的上下文长度增加了一倍，从 LLaMA1 的 2048 个 token 增加到了 4096。这使得 LLaMA2 能够处理更长的文本序列，改善了对长文本的理解和生成能力。</li><li><code>分组查询注意力（GQA，Grouped-Query Attention）</code>：通过将查询（query）分组并在组内共享键（key）和值（value），减少了计算量，同时保持了模型性能，提高了大型模型的推理效率。</li></ul><h4 id="通义千问"><a href="#通义千问" class="headerlink" title="通义千问"></a>通义千问</h4><blockquote><p><a target="_blank" rel="noopener" href="https://tongyi.aliyun.com/">通义千问使用地址</a></p></blockquote><blockquote><p><a href="https://github.com/QwenLM/Qwen1.5">通义千问开源地址</a></p></blockquote><p><strong>通义千问由阿里巴巴基于“通义”大模型研发</strong>，于 <code>2023 年 4 月</code>正式发布。2023 年 9 月，阿里云开源了 Qwen（通义千问）系列工作。并于 <code>2024 年 2 月 5 日</code>，开源了 <strong>Qwen1.5</strong>（Qwen2 的测试版）是一个 <strong>decoder-Only</strong> 的模型，采用 <code>SwiGLU 激活</code>、<code>RoPE</code>、<code>multi-head attention</code>的架构。中文能力相对来说非常不错的闭源模型。</p><p>目前，已经开源了 7 种模型大小：<strong>0.5B、1.8B、4B、7B、14B 、72B 的 Dense 模型和 14B (A2.7B)的 MoE 模型</strong>；所有模型均支持长度为 <strong>32768 token</strong> 的上下文；</p><h4 id="GLM-系列"><a href="#GLM-系列" class="headerlink" title="GLM 系列"></a>GLM 系列</h4><blockquote><p><a target="_blank" rel="noopener" href="https://chatglm.cn/">ChatGLM 使用地址</a></p></blockquote><blockquote><p><a href="https://github.com/THUDM">ChatGLM 开源地址</a></p></blockquote><p><strong>GLM 系列模型</strong>是<strong>清华大学和智谱 AI 等</strong>合作研发的语言大模型。2023 年 3 月 发布了 <strong>ChatGLM</strong>。2023 年 6 月发布了 <strong>ChatGLM 2</strong>。2023 年 10 月推出了 <strong>ChatGLM3</strong>。</p><p><strong>ChatGLM3-6B</strong> 支持正常的多轮对话的同时，原生支持工具调用（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。</p><p>开源了<code>对话模型</code> <strong>ChatGLM3-6B</strong>、<code>基础模型</code> <strong>ChatGLM3-6B-Base</strong>、<code>长文本对话模型</code> <strong>ChatGLM3-6B-32K</strong>、<code>多模态</code> <strong>CogVLM-17B</strong> 、以及 <code>智能体</code> <strong>AgentLM</strong> 等全面对标 OpenAI。</p><h4 id="Baichuan-系列"><a href="#Baichuan-系列" class="headerlink" title="Baichuan 系列"></a>Baichuan 系列</h4><blockquote><p><a target="_blank" rel="noopener" href="https://www.baichuan-ai.com/chat">百川使用地址</a></p></blockquote><blockquote><p><a href="https://github.com/baichuan-inc">百川开源地址</a></p></blockquote><p><strong>Baichuan</strong> 是由<strong>百川智能</strong>开发的<strong>开源可商用</strong>的语言大模型。其基于<strong>Transformer 解码器架构（decoder-only）</strong>。</p><p>2023 年 6 月 15 日发布了 <strong>Baichuan-7B</strong> 和 <strong>Baichuan-13B</strong>。百川同时开源了<strong>预训练</strong>和<strong>对齐</strong>模型，<code>预训练模型是面向开发者的“基座”</code>，而<code>对齐模型则面向广大需要对话功能的普通用户</code>。</p><p><strong>Baichuan2</strong> 于 <code>2023年 9 月 6 日</code>推出。发布了 <strong>7B、13B</strong> 的 <strong>Base</strong> 和 <strong>Chat</strong> 版本，并提供了 Chat 版本的 <strong>4bits 量化</strong>。</p><p><code>2024 年 1 月 29 日</code> 发布了 <strong>Baichuan 3</strong>。但是<strong>目前还没有开源</strong>。</p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E5%A5%BD%E5%A5%BD%E7%A0%81%E4%BB%A3%E7%A0%81%E5%90%96/" class="category-chain-item">好好码代码吖</a> <span>></span> <a href="/categories/%E5%A5%BD%E5%A5%BD%E7%A0%81%E4%BB%A3%E7%A0%81%E5%90%96/LLM/" class="category-chain-item">LLM</a> <span>></span> <a href="/categories/%E5%A5%BD%E5%A5%BD%E7%A0%81%E4%BB%A3%E7%A0%81%E5%90%96/LLM/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B/" class="category-chain-item">大模型简介</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/LLM/">#LLM</a> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">#人工智能</a></div></div><div class="license-box my-3"><div class="license-title"><div>大型语言模型（LLM）理论简介</div><div>https://github.com/yangxiangnanwill/yangxiangnanwill.github.io/2026/01/04/好好码代码吖/LLM/大模型简介/大型语言模型（LLM）理论简介/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>will</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2026年1月4日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2026/01/04/%E5%A5%BD%E5%A5%BD%E7%A0%81%E4%BB%A3%E7%A0%81%E5%90%96/Linux/%E5%AE%89%E8%A3%85Java8/" title="安装Java8"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">安装Java8</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2026/01/04/%E5%A5%BD%E5%A5%BD%E7%A0%81%E4%BB%A3%E7%A0%81%E5%90%96/JAVA/Ureport/Ureport%E6%8A%A5%E8%A1%A8/" title="Ureport报表"><span class="hidden-mobile">Ureport报表</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t){var e=Fluid.plugins.typing;(t=t.getElementById("subtitle"))&&e&&e(t.getAttribute("data-typed-text"))}((window,document))</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",function(){var t,o=jQuery("#toc");0!==o.length&&window.tocbot&&(t=jQuery("#board-ctn").offset().top,window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-t},CONFIG.toc)),0<o.find(".toc-list-item").length&&o.css("visibility","visible"),Fluid.events.registerRefreshCallback(function(){var t;"tocbot"in window&&(tocbot.refresh(),0!==(t=jQuery("#toc")).length)&&tocbot&&0<t.find(".toc-list-item").length&&t.css("visibility","visible")}))})</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback(function(){if("anchors"in window){anchors.removeAll();var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}})})</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",function(){Fluid.plugins.fancyBox()})</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>