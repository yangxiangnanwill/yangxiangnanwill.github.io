{
    "version": "https://jsonfeed.org/version/1",
    "title": "Will • All posts by \"人工智能\" tag",
    "description": "愿你一生努力，一生被爱",
    "home_page_url": "https://github.com/yangxiangnanwill/yangxiangnanwill.github.io",
    "items": [
        {
            "id": "https://github.com/yangxiangnanwill/yangxiangnanwill.github.io/2026/01/04/%E5%A5%BD%E5%A5%BD%E7%A0%81%E4%BB%A3%E7%A0%81%E5%90%96/LLM/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E7%90%86%E8%AE%BA%E7%AE%80%E4%BB%8B/",
            "url": "https://github.com/yangxiangnanwill/yangxiangnanwill.github.io/2026/01/04/%E5%A5%BD%E5%A5%BD%E7%A0%81%E4%BB%A3%E7%A0%81%E5%90%96/LLM/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E7%90%86%E8%AE%BA%E7%AE%80%E4%BB%8B/",
            "title": "大型语言模型（LLM）理论简介",
            "date_published": "2026-01-04T02:06:38.333Z",
            "content_html": "<h1 id=\"什么是大型语言模型（LLM）\"><a href=\"#什么是大型语言模型（LLM）\" class=\"headerlink\" title=\"什么是大型语言模型（LLM）\"></a>什么是大型语言模型（LLM）</h1><h2 id=\"大型语言模型（LLM）的概念\"><a href=\"#大型语言模型（LLM）的概念\" class=\"headerlink\" title=\"大型语言模型（LLM）的概念\"></a>大型语言模型（LLM）的概念</h2><p>大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型。</p>\n<p>LLM 通常指包含数百亿（或更多）参数的语言模型，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知名 LLM 有 GPT-3.5、GPT-4、PaLM、Claude 和 LLaMA 等，国内的有文心一言、讯飞星火、通义千问、ChatGLM、百川等。</p>\n<p>为了探索性能的极限，许多研究人员开始训练越来越庞大的语言模型，例如拥有 1750 亿参数的 GPT-3 和 5400 亿参数的 PaLM 。尽管这些大型语言模型与小型语言模型（例如 3.3 亿参数的 BERT 和 15 亿参数的 GPT-2）使用相似的架构和预训练任务，但它们展现出截然不同的能力，尤其在解决复杂任务时表现出了惊人的潜力，这被称为“涌现能力”。以 GPT-3 和 GPT-2 为例，GPT-3 可以通过学习上下文来解决少样本任务，而 GPT-2 在这方面表现较差。因此，科研界给这些庞大的语言模型起了个名字，称之为“大语言模型（LLM）”。LLM 的一个杰出应用就是 ChatGPT ，它是 GPT 系列 LLM 用于与人类对话式应用的大胆尝试，展现出了非常流畅和自然的表现。</p>\n<h2 id=\"LLM-的发展历程\"><a href=\"#LLM-的发展历程\" class=\"headerlink\" title=\"LLM 的发展历程\"></a>LLM 的发展历程</h2><p>语言建模的研究可以追溯到20 世纪 90 年代，当时的研究主要集中在采用统计学习方法来预测词汇，通过分析前面的词汇来预测下一个词汇。但在理解复杂语言规则方面存在一定局限性。</p>\n<p>随后，研究人员不断尝试改进，2003 年深度学习先驱 Bengio 在他的经典论文 《A Neural Probabilistic Language Model》中，首次将深度学习的思想融入到语言模型中。强大的神经网络模型，相当于为计算机提供了强大的”大脑”来理解语言，让模型可以更好地捕捉和理解语言中的复杂关系。</p>\n<p>2018 年左右，Transformer 架构的神经网络模型开始崭露头角。通过大量文本数据训练这些模型，使它们能够通过阅读大量文本来深入理解语言规则和模式，就像让计算机阅读整个互联网一样，对语言有了更深刻的理解，极大地提升了模型在各种自然语言处理任务上的表现。</p>\n<p>与此同时，研究人员发现，随着语言模型规模的扩大（增加模型大小或使用更多数据），模型展现出了一些惊人的能力，在各种任务中的表现均显著提升。这一发现标志着大型语言模型（LLM）时代的开启。</p>\n<h2 id=\"常见的-LLM-模型\"><a href=\"#常见的-LLM-模型\" class=\"headerlink\" title=\"常见的 LLM 模型\"></a>常见的 LLM 模型</h2><p>主要介绍几个国内外常见的大模型（包括开源和闭源）。</p>\n<h3 id=\"闭源-LLM-未公开源代码\"><a href=\"#闭源-LLM-未公开源代码\" class=\"headerlink\" title=\"闭源 LLM (未公开源代码)\"></a>闭源 LLM (未公开源代码)</h3><h4 id=\"GPT-系列\"><a href=\"#GPT-系列\" class=\"headerlink\" title=\"GPT 系列\"></a>GPT 系列</h4><p>OpenAI 公司在 2018 年提出的 GPT（Generative Pre-Training） 模型是典型的 生成式预训练语言模型 之一。</p>\n<p>GPT 模型的基本原则是通过语言建模将世界知识压缩到仅解码器 (decoder-only) 的 Transformer 模型中，这样它就可以恢复(或记忆)世界知识的语义，并充当通用任务求解器。它能够成功的两个关键点：</p>\n<ul>\n<li>训练能够准确预测下一个单词的 decoder-only 的 Transformer 语言模型</li>\n<li>扩展语言模型的大小</li>\n</ul>\n<h5 id=\"ChatGPT\"><a href=\"#ChatGPT\" class=\"headerlink\" title=\"ChatGPT\"></a>ChatGPT</h5><blockquote>\n<p><a href=\"https://chat.openai.com/\">ChatGPT 使用地址</a></p>\n</blockquote>\n<p><code>2022 年 11 月</code>，<strong>OpenAI</strong> 发布了基于 GPT 模型（GPT-3.5 和 GPT-4） 的<strong>会话应用 ChatGPT</strong>。由于与人类交流的出色能力，ChatGPT 自发布以来就引发了人工智能社区的兴奋。ChatGPT 是基于强大的 GPT 模型开发的，具有特别优化的会话能力。</p>\n<p>ChatGPT 从本质上来说是一个 LLM 应用，是基于基座模型开发出来的，与基座模型有本质的区别。其支持 GPT-3.5 和 GPT-4 两个版本。</p>\n<p>现在的 ChatGPT 支持最长达 32,000 个字符，知识截止日期是 2021 年 9 月，它可以执行各种任务，包括<strong>代码编写、数学问题求解、写作建议</strong>等。ChatGPT 在与人类交流方面表现出了卓越的能力：拥有丰富的知识储备，对数学问题进行推理的技能，在多回合对话中准确追踪上下文，并且与人类安全使用的价值观非常一致。后来，ChatGPT 支持插件机制，这进一步扩展了 ChatGPT 与现有工具或应用程序的能力。到目前为止，它似乎是人工智能历史上最强大的聊天机器人。ChatGPT 的推出对未来的人工智能研究具有重大影响，它为探索类人人工智能系统提供了启示。</p>\n<h5 id=\"GPT-4\"><a href=\"#GPT-4\" class=\"headerlink\" title=\"GPT-4\"></a>GPT-4</h5><p><code>2023 年 3 月</code>发布的 GPT-4，它将<strong>文本输入扩展到多模态信号</strong>。GPT3.5 拥有 1750 亿 个参数，而 GPT4 的参数量官方并没有公布，但有相关人员猜测，GPT-4 在 120 层中总共包含了 1.8 万亿参数，也就是说，GPT-4 的规模是 GPT-3 的 10 倍以上。因此，GPT-4 比 GPT-3.5 <strong>解决复杂任务的能力更强，在许多评估任务上表现出较大的性能提升</strong>。</p>\n<p>最近的一项研究通过对人为生成的问题进行定性测试来研究 GPT-4 的能力，这些问题包含了各种各样的困难任务，并表明 GPT-4 可以比之前的 GPT 模型(如 GPT3.5 )实现更优越的性能。此外，由于六个月的迭代校准(在 RLHF 训练中有额外的安全奖励信号)，GPT-4 对恶意或挑衅性查询的响应更安全，并应用了一些干预策略来缓解 LLM 可能出现的问题，如幻觉、隐私和过度依赖。</p>\n<blockquote>\n<p>注意：2023 年 11 月 7 日， OpenAI 召开了首个开发者大会，会上推出了最新的大语言模型 GPT-4 Turbo，Turbo 相当于进阶版。它将上下文长度扩展到 128k，相当于 300 页文本，并且训练知识更新到 2023 年 4 月</p>\n</blockquote>\n<p>GPT3.5 是免费的，而 GPT-4 是收费的。需要开通 plus 会员 20 美元&#x2F;月。</p>\n<h4 id=\"Claude系列\"><a href=\"#Claude系列\" class=\"headerlink\" title=\"Claude系列\"></a>Claude系列</h4><p>Claude 系列模型是由 OpenAI 离职人员创建的 <strong>Anthropic</strong> 公司开发的闭源语言大模型。</p>\n<blockquote>\n<p><a href=\"https://claude.ai/chats\">Claude 使用地址</a></p>\n</blockquote>\n<p>最早的 <strong>Claude</strong> 于 <code>2023 年 3 月 15 日</code>发布，在 2023 年 7 月 11 日，更新至 <strong>Claude-2</strong>， 并在 <code>2024 年 3 月 4 日</code>更新至 <strong>Claude-3</strong>。</p>\n<p>Claude 3 系列包括三个不同的模型，分别是 Claude 3 Haiku、Claude 3 Sonnet 和 Claude 3 Opus，它们的能力依次递增，旨在满足不同用户和应用场景的需求。</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">模型名称</th>\n<th align=\"center\">上下文长度</th>\n<th align=\"center\">特点</th>\n<th align=\"center\">input 费用($&#x2F;1M tokens)</th>\n<th align=\"center\">output 费用($&#x2F;1M tokens)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">Claude 3 Haiku</td>\n<td align=\"center\">200k</td>\n<td align=\"center\">速度最快</td>\n<td align=\"center\">0.25</td>\n<td align=\"center\">1.25</td>\n</tr>\n<tr>\n<td align=\"center\">Claude 3 Sonnet</td>\n<td align=\"center\">200k</td>\n<td align=\"center\">平衡</td>\n<td align=\"center\">3git</td>\n<td align=\"center\">15</td>\n</tr>\n<tr>\n<td align=\"center\">Claude 3 Opus</td>\n<td align=\"center\">200k</td>\n<td align=\"center\">性能最强</td>\n<td align=\"center\">15</td>\n<td align=\"center\">75</td>\n</tr>\n</tbody></table>\n<h4 id=\"PaLM-x2F-Gemini-系列\"><a href=\"#PaLM-x2F-Gemini-系列\" class=\"headerlink\" title=\"PaLM&#x2F;Gemini 系列\"></a>PaLM&#x2F;Gemini 系列</h4><p><strong>PaLM 系列</strong>语言大模型由 <strong>Google</strong> 开发。其初始版本于 <code>2022 年 4 月</code>发布，并在 2023 年 3 月公开了 API。2023 年 5 月，Google 发布了 <strong>PaLM 2</strong>，<code>2024 年 2 月 1 日</code>，Google 将 Bard(之前发布的对话应用) 的底层大模型驱动由 PaLM2 更改为 <strong>Gemini</strong>，同时也将原先的 Bard 更名为 <strong>Gemini</strong>。</p>\n<blockquote>\n<p><a href=\"https://ai.google/discover/palm2/\">PaLM 官方地址</a></p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://gemini.google.com/\">Gemini 使用地址</a></p>\n</blockquote>\n<p>目前的 Gemini 是第一个版本，即 Gemini 1.0，根据参数量不同分为 Ultra, Pro 和 Nano 三个版本。</p>\n<h4 id=\"文心一言\"><a href=\"#文心一言\" class=\"headerlink\" title=\"文心一言\"></a>文心一言</h4><blockquote>\n<p><a href=\"https://yiyan.baidu.com/\">文心一言使用地址</a></p>\n</blockquote>\n<p><strong>文心一言是基于百度文心大模型的知识增强语言大模型</strong>，于 <code>2023 年 3 月</code>在国内率先开启邀测。文心一言的基础模型文心大模型于 2019 年发布 1.0 版，现已更新到 <strong>4.0</strong> 版本。更进一步划分，文心大模型包括 NLP 大模型、CV 大模型、跨模态大模型、生物计算大模型、行业大模型。中文能力相对来说非常不错的闭源模型。</p>\n<p>文心一言网页版分为<strong>免费版</strong>和<strong>专业版</strong>。</p>\n<ul>\n<li>免费版使用文心 3.5 版本，已经能够满足个人用户或小型企业的大部分需求。</li>\n<li>专业版使用文心 4.0 版本。定价为 59.9 元&#x2F;月，连续包月优惠价为 49.9 元&#x2F;月</li>\n</ul>\n<p>同时也可以使用 API 进行调用（<a href=\"https://console.bce.baidu.com/qianfan/chargemanage/list\">计费详情</a>）。</p>\n<h4 id=\"星火大模型\"><a href=\"#星火大模型\" class=\"headerlink\" title=\"星火大模型\"></a>星火大模型</h4><blockquote>\n<p><a href=\"https://xinghuo.xfyun.cn/\">星火大模型使用地址</a></p>\n</blockquote>\n<p><strong>讯飞星火认知大模型</strong>是<strong>科大讯飞</strong>发布的语言大模型，支持多种自然语言处理任务。该模型于 <code>2023 年 5 月</code>首次发布，后续经过多次升级。<code>2023 年 10 月</code>，讯飞发布了<strong>讯飞星火认知大模型 V3.0</strong>。<code>2024 年 1 月</code>，讯飞发布了<strong>讯飞星火认知大模型 V3.5</strong>，在语言理解，文本生成，知识问答等七个方面进行了升级，并且支持 system 指令，插件调用等多项功能。</p>\n<h3 id=\"开源LLM\"><a href=\"#开源LLM\" class=\"headerlink\" title=\"开源LLM\"></a>开源LLM</h3><h4 id=\"LLaMA-系列\"><a href=\"#LLaMA-系列\" class=\"headerlink\" title=\"LLaMA 系列\"></a>LLaMA 系列</h4><blockquote>\n<p><a href=\"https://llama.meta.com/\">LLaMA 官方地址</a></p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://github.com/facebookresearch/llama\">LLaMA 开源地址</a></p>\n</blockquote>\n<p><strong>LLaMA 系列模型</strong>是 <strong>Meta</strong> 开源的一组参数规模 <strong>从 7B 到 70B</strong> 的基础语言模型。LLaMA 于<code>2023 年 2 月</code>发布，并于 <code>2023 年 7 月</code>发布了 <strong>LLaMA2</strong> 模型。它们都是在数万亿个字符上训练的，展示了如何<strong>仅使用公开可用的数据集来训练最先进的模型</strong>，而不需要依赖专有或不可访问的数据集。这些数据集包括 Common Crawl、Wikipedia、OpenWebText2、RealNews、Books 等。LLaMA 模型使用了<strong>大规模的数据过滤和清洗技术</strong>，以提高数据质量和多样性，减少噪声和偏见。LLaMA 模型还使用了高效的<strong>数据并行</strong>和<strong>流水线并行</strong>技术，以加速模型的训练和扩展。特别地，LLaMA 13B 在 CommonsenseQA 等 9 个基准测试中超过了 GPT-3 (175B)，而 <strong>LLaMA 65B 与最优秀的模型 Chinchilla-70B 和 PaLM-540B 相媲美</strong>。LLaMA 通过使用更少的字符来达到最佳性能，从而在各种推理预算下具有优势。</p>\n<p>与 GPT 系列相同，LLaMA 模型也采用了 <strong>decoder-only</strong> 架构，同时结合了一些前人工作的改进：</p>\n<ul>\n<li><code>Pre-normalization 正则化</code>：为了提高训练稳定性，LLaMA 对每个 Transformer 子层的输入进行了 RMSNorm 归一化，这种归一化方法可以避免梯度爆炸和消失的问题，提高模型的收敛速度和性能；</li>\n<li><code>SwiGLU 激活函数</code>：将 ReLU 非线性替换为 SwiGLU 激活函数，增加网络的表达能力和非线性，同时减少参数量和计算量；</li>\n<li><code>旋转位置编码（RoPE，Rotary Position Embedding）</code>：模型的输入不再使用位置编码，而是在网络的每一层添加了位置编码，RoPE 位置编码可以有效地捕捉输入序列中的相对位置信息，并且具有更好的泛化能力。</li>\n</ul>\n<p><strong>LLaMA2</strong> 在 LLaMA 系列模型的基础上进行了改进，提高了模型的性能和效率：</p>\n<ul>\n<li><code>更多的训练数据量</code>：LLaMA2 在 2 万亿个 token 的数据上进行预训练，相比 LLaMA1 的训练数据量增加了 40%。LLaMA2 能够接触到更多的文本信息，从而提高了其理解和生成文本的能力。</li>\n<li><code>更长的上下文长度</code>：LLaMA2 的上下文长度增加了一倍，从 LLaMA1 的 2048 个 token 增加到了 4096。这使得 LLaMA2 能够处理更长的文本序列，改善了对长文本的理解和生成能力。</li>\n<li><code>分组查询注意力（GQA，Grouped-Query Attention）</code>：通过将查询（query）分组并在组内共享键（key）和值（value），减少了计算量，同时保持了模型性能，提高了大型模型的推理效率。</li>\n</ul>\n<h4 id=\"通义千问\"><a href=\"#通义千问\" class=\"headerlink\" title=\"通义千问\"></a>通义千问</h4><blockquote>\n<p><a href=\"https://tongyi.aliyun.com/\">通义千问使用地址</a></p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://github.com/QwenLM/Qwen1.5\">通义千问开源地址</a></p>\n</blockquote>\n<p><strong>通义千问由阿里巴巴基于“通义”大模型研发</strong>，于 <code>2023 年 4 月</code>正式发布。2023 年 9 月，阿里云开源了 Qwen（通义千问）系列工作。并于 <code>2024 年 2 月 5 日</code>，开源了 <strong>Qwen1.5</strong>（Qwen2 的测试版）是一个 <strong>decoder-Only</strong> 的模型，采用 <code>SwiGLU 激活</code>、<code>RoPE</code>、<code>multi-head attention</code>的架构。中文能力相对来说非常不错的闭源模型。</p>\n<p>目前，已经开源了 7 种模型大小：<strong>0.5B、1.8B、4B、7B、14B 、72B 的 Dense 模型和 14B (A2.7B)的 MoE 模型</strong>；所有模型均支持长度为 <strong>32768 token</strong> 的上下文；</p>\n<h4 id=\"GLM-系列\"><a href=\"#GLM-系列\" class=\"headerlink\" title=\"GLM 系列\"></a>GLM 系列</h4><blockquote>\n<p><a href=\"https://chatglm.cn/\">ChatGLM 使用地址</a></p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://github.com/THUDM\">ChatGLM 开源地址</a></p>\n</blockquote>\n<p><strong>GLM 系列模型</strong>是<strong>清华大学和智谱 AI 等</strong>合作研发的语言大模型。2023 年 3 月 发布了 <strong>ChatGLM</strong>。2023 年 6 月发布了 <strong>ChatGLM 2</strong>。2023 年 10 月推出了 <strong>ChatGLM3</strong>。</p>\n<p><strong>ChatGLM3-6B</strong> 支持正常的多轮对话的同时，原生支持工具调用（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。</p>\n<p>开源了<code>对话模型</code> <strong>ChatGLM3-6B</strong>、<code>基础模型</code> <strong>ChatGLM3-6B-Base</strong>、<code>长文本对话模型</code> <strong>ChatGLM3-6B-32K</strong>、<code>多模态</code> <strong>CogVLM-17B</strong> 、以及 <code>智能体</code> <strong>AgentLM</strong> 等全面对标 OpenAI。</p>\n<h4 id=\"Baichuan-系列\"><a href=\"#Baichuan-系列\" class=\"headerlink\" title=\"Baichuan 系列\"></a>Baichuan 系列</h4><blockquote>\n<p><a href=\"https://www.baichuan-ai.com/chat\">百川使用地址</a></p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://github.com/baichuan-inc\">百川开源地址</a></p>\n</blockquote>\n<p><strong>Baichuan</strong> 是由<strong>百川智能</strong>开发的<strong>开源可商用</strong>的语言大模型。其基于<strong>Transformer 解码器架构（decoder-only）</strong>。</p>\n<p>2023 年 6 月 15 日发布了 <strong>Baichuan-7B</strong> 和 <strong>Baichuan-13B</strong>。百川同时开源了<strong>预训练</strong>和<strong>对齐</strong>模型，<code>预训练模型是面向开发者的“基座”</code>，而<code>对齐模型则面向广大需要对话功能的普通用户</code>。</p>\n<p><strong>Baichuan2</strong> 于 <code>2023年 9 月 6 日</code>推出。发布了 <strong>7B、13B</strong> 的 <strong>Base</strong> 和 <strong>Chat</strong> 版本，并提供了 Chat 版本的 <strong>4bits 量化</strong>。</p>\n<p><code>2024 年 1 月 29 日</code> 发布了 <strong>Baichuan 3</strong>。但是<strong>目前还没有开源</strong>。</p>\n",
            "tags": [
                "LLM",
                "人工智能"
            ]
        }
    ]
}